import streamlit as st
import os
from dotenv import load_dotenv
from ingestion import load_documents, split_documents, chunk_and_vectorstore
import time

# Page configuration
st.set_page_config(
    page_title="Document Indexing Pipeline",
    page_icon="ğŸ“š",
    layout="wide"
)

# Load environment variables
load_dotenv()

def main():
    st.title("ğŸ“š Document Indexing Pipeline")
    st.markdown("---")
    
    # Sidebar for configuration
    with st.sidebar:
        st.header("âš™ï¸ Configuration")
        
        # Check if environment variables are set
        conn_str = os.getenv("AZURE_STORAGE_CONNECTION_STRING")
        container = os.getenv("AZURE_STORAGE_CONTAINER_NAME")
        azure_openai_key = os.getenv("AZURE_OPENAI_API_KEY")
        azure_openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        pinecone_key = os.getenv("PINECONE_API_KEY")
        pinecone_index = os.getenv("PINECONE_INDEX_NAME")
        
        if conn_str and container:
            st.success("âœ… Azure Storage configured")
            st.info(f"Container: {container}")
        else:
            st.error("âŒ Azure Storage not configured")
            st.warning("Please set AZURE_STORAGE_CONNECTION_STRING and AZURE_STORAGE_CONTAINER_NAME in your .env file")
        
        if azure_openai_key and azure_openai_endpoint:
            st.success("âœ… Azure OpenAI configured")
            st.info(f"Endpoint: {azure_openai_endpoint[:50]}...")
        else:
            st.warning("âš ï¸ Azure OpenAI not configured")
        
        if pinecone_key and pinecone_index:
            st.success("âœ… Pinecone configured")
            st.info(f"Index: {pinecone_index}")
        else:
            st.warning("âš ï¸ Pinecone not configured")
    
    # Main content area
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸš€ Start Indexing")
        st.markdown("""
        This pipeline will:
        1. Load documents from Azure Blob Storage
        2. Process and split documents into chunks
        3. Create embeddings and store in vector database
        """)
        
        # Indexing button
        if st.button("ğŸ”„ Start Indexing", type="primary", use_container_width=True):
            if not conn_str or not container:
                st.error("âŒ Cannot start indexing: Azure Storage not configured")
                return
            
            if not azure_openai_key or not azure_openai_endpoint:
                st.error("âŒ Cannot start indexing: Azure OpenAI not configured")
                return
            
            if not pinecone_key or not pinecone_index:
                st.error("âŒ Cannot start indexing: Pinecone not configured")
                return
            
            # Create progress containers
            progress_container = st.container()
            status_container = st.container()
            results_container = st.container()
            
            with progress_container:
                progress_bar = st.progress(0)
                status_text = st.empty()
            
            with status_container:
                st.info("ğŸ”„ Starting indexing process...")
            
            try:
                # Step 1: Load documents
                status_text.text("ğŸ“¥ Loading documents from Azure Blob Storage...")
                progress_bar.progress(25)
                
                docs = load_documents()
                st.success(f"âœ… Loaded {len(docs)} documents")
                
                # Step 2: Split documents
                status_text.text("âœ‚ï¸ Splitting documents into chunks...")
                progress_bar.progress(50)
                
                chunks = split_documents(docs)
                st.success(f"âœ… Created {len(chunks)} chunks")
                
                # Step 3: Create embeddings and store in vector database
                status_text.text("ğŸ§  Creating embeddings and storing in vector database...")
                progress_bar.progress(75)
                
                chunk_and_vectorstore(chunks)
                st.success("âœ… Documents indexed in vector database")
                
                # Step 4: Complete
                status_text.text("âœ… Indexing completed!")
                progress_bar.progress(100)
                
                # Final results
                with results_container:
                    st.success("ğŸ‰ Indexing completed successfully!")
                    
                    # Display statistics
                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        st.metric("Documents", len(docs))
                    with col_b:
                        st.metric("Chunks", len(chunks))
                    with col_c:
                        st.metric("Status", "âœ… Complete")
                    
                    # Show sample chunks
                    if chunks:
                        st.subheader("ğŸ“„ Sample Chunks")
                        for i, chunk in enumerate(chunks[:3]):  # Show first 3 chunks
                            with st.expander(f"Chunk {i+1} (Length: {len(chunk.page_content)} chars)"):
                                st.text(chunk.page_content[:500] + "..." if len(chunk.page_content) > 500 else chunk.page_content)
                
                status_text.text("âœ… Indexing completed!")
                
            except Exception as e:
                st.error(f"âŒ Error during indexing: {str(e)}")
                status_text.text("âŒ Indexing failed!")
    
    with col2:
        st.header("ğŸ“Š Pipeline Status")
        
        # Check system status
        st.subheader("System Status")
        
        # Check Azure connection
        if conn_str and container:
            st.success("ğŸŸ¢ Azure Storage: Connected")
        else:
            st.error("ğŸ”´ Azure Storage: Not configured")
        
        # Check required packages
        try:
            import langchain_community
            import langchain_openai
            import langchain_pinecone
            import pinecone
            st.success("ğŸŸ¢ Dependencies: All installed")
        except ImportError as e:
            st.error(f"ğŸ”´ Dependencies: Missing - {str(e)}")
        
        # Check API keys
        if azure_openai_key and azure_openai_endpoint:
            st.success("ğŸŸ¢ Azure OpenAI: Configured")
        else:
            st.error("ğŸ”´ Azure OpenAI: Not configured")
        
        if pinecone_key and pinecone_index:
            st.success("ğŸŸ¢ Pinecone: Configured")
        else:
            st.error("ğŸ”´ Pinecone: Not configured")
        
        st.subheader("ğŸ“ˆ Statistics")
        st.info("Run indexing to see statistics")
        
        # Instructions
        st.subheader("ğŸ“‹ Instructions")
        st.markdown("""
        1. Ensure your `.env` file contains:
           - `AZURE_STORAGE_CONNECTION_STRING`
           - `AZURE_STORAGE_CONTAINER_NAME`
           - `AZURE_OPENAI_API_KEY`
           - `AZURE_OPENAI_ENDPOINT`
           - `PINECONE_API_KEY`
           - `PINECONE_INDEX_NAME`
        2. Click "Start Indexing" to begin
        3. Monitor progress in real-time
        4. View results and statistics
        """)

if __name__ == "__main__":
    main()
